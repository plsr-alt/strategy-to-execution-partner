# PoC計画書

**作成日**: 2026-02-20
**期間**: 4週間（推奨）
**目的**: 技術的実現可能性の検証と最適構成の特定

---

## 1. PoC成功条件（定量KPI）

| KPI | 目標値 | 測定方法 | Go/NoGo |
|-----|--------|---------|---------|
| 項目抽出精度（F1） | ≥ 85% | 評価セット50件で測定 | 未達→構成見直し |
| 1件あたり処理時間 | ≤ 30秒/件（バッチ） | 実測平均 | 超過→ボトルネック特定 |
| 例外率（抽出失敗） | ≤ 15% | ログ集計 | 超過→前処理改善 |
| 再現性 | 同一入力で同一出力 | 5回同一テスト実行 | NG→LLMパラメータ固定 |
| 監査ログ完全性 | 全件ログ記録 | ログDB件数≥処理件数 | 欠損→ログ設計修正 |
| 人手確認時間削減率 | ≥ 20%（現状比） | Before/After計測 | 未達→UI改善 |

---

## 2. 検証項目

### 2-1. データ抽出
- [ ] OCR精度: Textract vs PaddleOCR on 評価セット（50件）
- [ ] 前処理効果: 傾き補正・二値化ありなし比較
- [ ] フォーマット別精度: 手順書タイプA/B（仮定：2種類）
- [ ] 画質劣化耐性: 低解像度・圧縮劣化画像での精度

### 2-2. LLM正規化
- [ ] JSONスキーマ適合率: 出力が期待スキーマに合致する率
- [ ] 項目揺れ吸収: 「氏名」「お名前」「name」が同一キーに正規化されるか
- [ ] confidence スコアの信頼性: スコアと実際の正誤の相関
- [ ] 日本語固有表現の処理: 日付（令和/西暦）、数字（全角/半角）
- [ ] 欠損検知精度: 必須項目が抽出できない場合のフラグ精度

### 2-3. データ反映
- [ ] CSV出力の正確性: 抽出値とCSV値の一致確認
- [ ] Google Sheets API連携の動作確認
- [ ] 確認UIでの訂正→再出力フロー
- [ ] （Phase2準備）既存システムAPIへのPOST動作確認

### 2-4. 例外処理
- [ ] 低画質画像のフォールバック動作（アラート発火確認）
- [ ] LLMタイムアウト時のリトライ動作
- [ ] 部分的抽出失敗時の人手エスカレーション動作
- [ ] 必須項目欠損時の処理停止・通知

### 2-5. PII・セキュリティ
- [ ] PII項目（氏名・住所等）の識別・マスキング処理確認
- [ ] 通信経路の暗号化（S3/Textract/Bedrock すべてTLS）
- [ ] IAMロール最小権限の確認
- [ ] ログにPIIが混入していないか確認

### 2-6. 運用性
- [ ] エラー発生時のアラート（CloudWatch → 通知）
- [ ] ログ検索性（DynamoDB/CloudWatch Insightsでの検索テスト）
- [ ] 設定変更の容易性（スキーマ変更→デプロイ時間）

---

## 3. 週次計画（4週間）

### Week 1: 環境構築・評価セット作成
```
目標: PoC環境を動作させ、評価用データセットを準備する

タスク:
□ AWS環境構築（S3 / Lambda / Textract / Bedrock）
□ 評価セット収集（実際の手順書画像 50件）
□ 正解データ（Ground Truth）の人手作成（20件分）
□ 前処理パイプライン実装（傾き補正・ノイズ除去）
□ Textract基本動作確認（Key-Value抽出テスト）

成果物:
- 動作する最小パイプライン（S3 → Textract → JSON）
- 評価セット50件（正解付き20件含む）
- 環境構築手順書
```

### Week 2: OCR・LLM精度検証
```
目標: 各方式の精度を定量評価し、採用構成を決定する

タスク:
□ Textract vs PaddleOCR 精度比較（20件評価セット）
□ LLMプロンプト設計・Few-shot例作成
□ Claude on Bedrock 正規化テスト（スキーマ適合率測定）
□ confidence スコア閾値の仮設定
□ 日付・数値の正規化パターン実装

成果物:
- 精度比較レポート（定量値）
- 採用OCR方式の決定（ADR記録）
- LLMプロンプト v1.0
- confidence スコア分布グラフ
```

### Week 3: 統合パイプライン・確認UI構築
```
目標: End-to-End パイプラインと確認UIを動作させる

タスク:
□ Step Functions でパイプライン統合（S3→前処理→OCR→LLM→DB）
□ 確認UI実装（Flask/Next.js）: 抽出結果表示・訂正・承認
□ CSV/Sheets出力実装
□ 監査ログDB設計・実装（DynamoDB）
□ エラー通知設計（CloudWatch Alarm → SNS）

成果物:
- 動作するEnd-to-Endパイプライン
- 確認UI（ブラウザ動作）
- ログDB（全件記録確認）
```

### Week 4: 本番データ検証・評価・Go/NoGo判断
```
目標: 本番相当データで評価し、Go/NoGo判断材料を揃える

タスク:
□ 残り30件の正解データ付与
□ 50件全件での精度評価（F1, 例外率, 処理時間）
□ PII・セキュリティチェック（ペネトレテスト簡易版）
□ Before/After 作業時間計測（オペレーター1名）
□ 評価レポート作成
□ Go/NoGo 判断会議

成果物:
- PoC評価レポート（定量KPI達成状況）
- デモ動画（5分）
- Go/NoGo 判断書（推奨含む）
- Phase 1 MVP への引き継ぎ事項リスト
```

---

## 4. 必要リソース

| 役割 | 人数 | 工数 | スキル要件 |
|------|------|------|-----------|
| テックリード | 1 | 4週×80% | AWS / Python / LLM API |
| バックエンドエンジニア | 1 | 4週×100% | Python / Lambda / DynamoDB |
| フロントエンドエンジニア | 1 | Week3〜4×50% | React or Flask |
| 業務担当者（評価協力） | 1 | 週2時間 | 手順書業務知識 |
| セキュリティレビュー | 1 | Week4×20% | AWS IAM / セキュリティ |

### 技術環境
| リソース | 用途 | 見積もりコスト |
|---------|------|--------------|
| AWS S3 | 画像保存 | ~$5/月 |
| AWS Textract | OCR（50件×10p想定） | ~$10 |
| Amazon Bedrock (Claude) | LLM正規化（50件） | ~$20 |
| AWS Lambda | オーケストレーション | ~$5 |
| DynamoDB | ログ | ~$5 |
| 合計PoC期間 | | **~$50（4週間）** |

---

## 5. 想定成果物（PoC完了時）

| 成果物 | 形式 | 目的 |
|--------|------|------|
| PoC評価レポート | Markdown/PDF | Go/NoGo判断根拠 |
| 精度評価データ | CSV | 定量KPI記録 |
| デモ動画 | MP4 5分 | 社内説明・提案 |
| アーキテクチャ確定版 | Draw.io/Markdown | 実装引き継ぎ |
| ADR記録 | `decisions/` | 意思決定追跡 |
| コード（PoC版） | GitHub | 実装引き継ぎ |
| Go/NoGo判断書 | Markdown | 意思決定文書 |

---

## 6. Go/NoGo 判断基準

| 判断 | 条件 |
|------|------|
| **Go（MVP開発へ）** | F1 ≥ 85% かつ 例外率 ≤ 15% かつ オペレーター満足度「使いたい」 |
| **条件付きGo** | F1 70〜85% / 特定フォームに限定してMVP開発 |
| **PoC延長** | F1 < 70% / 根本課題特定済みで改善見込みあり |
| **NoGo** | 精度改善の見込みなし / セキュリティ上の懸念解消不能 |
