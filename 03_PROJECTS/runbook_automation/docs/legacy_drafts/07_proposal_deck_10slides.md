# 社内提案資料 — Runbook自動化プロジェクト
## 10スライド構成

**作成日**: 2026-02-20
**対象読者**: 経営層・事業部門長・情報システム担当
**想定発表時間**: 20〜30分

---

---

# Slide 1: 背景と課題

## タイトル
**手順書入力業務、このままでいいですか？**

## 箇条書き（3〜5点）
- 社内の手順書（画面キャプチャ含む）を「見ながら手入力」する業務が存在する
- 件数・種類の増加に伴い、担当者の工数が増大している
- 入力ミスによる後工程の手戻りが発生している
- 手順を知っている担当者に依存しており、引き継ぎが困難（属人化）
- DX推進の掛け声とは裏腹に、この業務だけ人力で止まっている

## 図解案
**図の種類**: 現状業務フロー図（Before）
**描く内容**:
```
[手順書（紙/画像）] → [担当者が目視確認] → [システムに手入力] → [チェック担当者が確認] → [エラー時は差し戻し]
                                                                          ↑
                                                              ここで毎回ミスが発生
```
*矢印の途中に「ボトルネック」「属人化」「ミス発生」のバルーンを配置*

## トークトラック（30〜60秒）
「みなさんの部門でも、手順書を見ながらシステムに入力する業務があると思います。件数が少ないうちは問題ありませんでしたが、業務量の増加とともに、入力ミスの増加・担当者の残業・引き継ぎ困難という3つの問題が顕在化してきました。この業務を放置すると、スケールできない・品質が安定しない・人に依存するという状況が続きます。今日は、この課題をテクノロジーで根本解決する提案をします。」

---

---

# Slide 2: 現状の問題構造

## タイトル
**問題は「人が悪い」のではなく「仕組みが時代遅れ」**

## 箇条書き（3〜5点）
- 根本原因①: 手順書フォーマットが機械可読でない（画像・PDF）
- 根本原因②: 人がデータ変換（画像→テキスト→入力値）を担っている
- 根本原因③: ミス検知の仕組みがなく、後で発覚する
- 症状: 担当者の集中力低下 / 繁忙期の品質劣化 / ベテランへの依存
- 構造的問題: この問題は担当者を変えても解決しない

## 図解案
**図の種類**: Why-Why分析（根本原因マップ）/ 魚の骨図
**描く内容**:
```
                   ┌─ 担当者スキル差
入力ミスが多い ──┤─ チェック機能なし
                   └─ 入力量が多く集中力が続かない

                   ┌─ 手順書が画像形式
属人化している ──┤─ 暗黙知が多い
                   └─ 引き継ぎドキュメントなし
```
*原因を「人要因」と「仕組み要因」に色分けして視覚化*

## トークトラック（30〜60秒）
「担当者を責めても解決しません。問題の本質は、手順書が画像形式であるため機械が読めず、人間がデータ変換を担わざるを得ない構造にあります。人が変換を担うということは、疲労・スキル差・集中力の影響を受けます。これは仕組みの問題です。仕組みを直す提案をします。」

---

---

# Slide 3: To-Be全体像

## タイトル
**入力業務の3段階自動化ロードマップ**

## 箇条書き（3〜5点）
- Phase 1（3ヶ月）: 入力支援 — AIが抽出した値を担当者が確認・コピー
- Phase 2（6ヶ月）: 半自動 — 高精度な項目は自動入力、疑わしい項目だけ人手確認
- Phase 3（1年）: 全自動 — 例外のみ人手。フィードバックで精度継続改善
- 段階的移行なのでリスクが低い。どのフェーズでも停止・ロールバック可能
- 最終的には入力時間を70%削減、ミス率を1/10以下にすることが目標

## 図解案
**図の種類**: フェーズ遷移図（横軸: 時間、縦軸: 自動化率）
**描く内容**:
```
自動化率
 100% |                                    ████ Phase3
  70% |                        ████████████
  30% |            ████████████
   0% |████████████
      |────────────┼───────────┼────────────┼──→ 時間
     現状        3ヶ月       6ヶ月       12ヶ月
                Phase1      Phase2      Phase3
```
*各フェーズに「価値」ラベルを追加（ミス削減/時間削減/コスト削減）*

## トークトラック（30〜60秒）
「自動化を一気に進めるのはリスクが高いので、3段階で進めます。まず3ヶ月でAIが抽出した値を担当者が確認するだけの『入力支援』から始めます。この時点でも作業時間は30%削減できます。その後、精度が確認できた項目から自動化を進め、最終的には担当者は例外処理だけ行う体制を目指します。」

---

---

# Slide 4: 方式比較

## タイトル
**技術選定: 4方式を比較、最適な組合せを特定**

## 箇条書き（3〜5点）
- 画像からの文字抽出（OCR）: AWS Textract vs Google Vision vs OSS（PaddleOCR）
- 構造化・正規化: LLM（Claude on Bedrock）で項目揺れを吸収、JSON化
- データ反映: CSV→Sheets（初期）→ API直接登録（本格運用）→ RPA（API非対応限定）
- 選定基準: 日本語精度・コスト・PII対応・スケーラビリティ・保守性
- 結論: Textract（OCR）＋ Claude on Bedrock（正規化）＋ Sheets→API（反映）の組合せが最適

## 図解案
**図の種類**: 比較スコアカード（レーダーチャート or 表）
**描く内容**:
```
        OCR方式比較（5段階）
               精度
                5
        コスト4   4保守性
          3         3
        PII 2   2 スケール
                1
             日本語

  ─── Textract  --- PaddleOCR  ··· ABBYY
```
*Textractが全体的にバランス良いことを視覚化*

## トークトラック（30〜60秒）
「技術の選択肢は多いですが、今回は3軸で比較しました。OCRはAWS Textractが日本語精度・保守性・コストのバランスが最も良い。正規化はAnthropicのClaudeモデルがAmazon Bedrock経由で使え、日本語の構造化出力に優れている。反映方式はまずCSV/Sheetsで素早く価値を出し、APIが使えるシステムは順次直接連携に移行します。」

---

---

# Slide 5: 推奨案

## タイトル
**推奨構成: AWS Textract × Claude × 段階的自動化**

## 箇条書き（3〜5点）
- OCR: AWS Textract（Key-Value抽出機能）→ 日本語フォームに対応、信頼スコア付き
- 正規化: Amazon Bedrock上のClaude claude-sonnet-4-6 → 項目揺れ吸収・JSON化・欠損検知
- 人手介入: confidence低い項目のみ確認UI表示 → オペレーター負荷を最小化
- 監査: 全ステップのログをDynamoDBに記録 → いつ・誰が・何を変更したか追跡可能
- 拡張性: AWSサービスを疎結合で組合せ → 特定ベンダーに依存しない設計

## 図解案
**図の種類**: アーキテクチャダイアグラム（簡略版）
**描く内容**:
```
[画像/PDF]
    ↓
[S3] → [Lambda] → [Textract] → [Bedrock/Claude]
                                      ↓
                              [confidence判定]
                              ↓           ↓
                          高精度       要確認
                            ↓            ↓
                         自動通過    [確認UI]
                              ↓           ↓
                        [Sheets/API出力] ← 承認
                              ↓
                        [監査ログ(DynamoDB)]
```

## トークトラック（30〜60秒）
「推奨アーキテクチャはシンプルです。画像をS3に入れると自動でTextractがOCRし、Claudeが正規化します。信頼度が高い項目は自動出力、低い項目だけ担当者に確認を求めます。全ステップの記録が残るので、後から何があったか追跡できます。AWSのマネージドサービスを使うので、自前でサーバーを管理する必要がありません。」

---

---

# Slide 6: MVP設計

## タイトル
**まず3ヶ月で『入力支援』を作る**

## 箇条書き（3〜5点）
- 対象: 1種類の手順書フォーマット（最も件数が多いもの1つ）
- 機能: 画像アップロード → 抽出結果をSheetsに出力 → 担当者が確認・コピー
- 非対象: 自動登録・複数フォーマット・リアルタイム処理（後回し）
- 成功条件: F1精度≥85% / 作業時間20%削減 / 「使いたい」70%以上
- コスト: 初期構築 約X万円 + 月次運用 約Y万円（PoC後に詳細試算）

## 図解案
**図の種類**: スコープ図（IN/OUTを視覚的に分ける）
**描く内容**:
```
┌─────────────────────────────────┐
│        MVP スコープ（IN）        │
│  ✅ 1フォーマット OCR            │
│  ✅ LLM正規化                   │
│  ✅ Sheets出力                  │
│  ✅ 確認UI（簡易版）             │
│  ✅ 基本的な監査ログ             │
└─────────────────────────────────┘
┌─────────────────────────────────┐
│       MVP スコープ外（OUT）      │
│  ❌ 自動登録（API）              │
│  ❌ 複数フォーマット対応          │
│  ❌ RPA                         │
│  ❌ 学習ループ                   │
└─────────────────────────────────┘
```

## トークトラック（30〜60秒）
「MVPは絞り込みが命です。最初から全部やろうとすると6ヶ月かかって何も出ません。まず3ヶ月で、1種類の手順書に特化した『抽出→確認→Sheets出力』だけを作ります。これだけでも入力ミスは大幅に減り、作業時間も短縮できます。担当者に使ってもらいながら改善する設計です。」

---

---

# Slide 7: PoC計画

## タイトル
**まず4週間で技術を検証する**

## 箇条書き（3〜5点）
- Week 1: 環境構築 + 評価セット50件作成
- Week 2: OCR比較（Textract vs PaddleOCR）+ LLM正規化テスト
- Week 3: End-to-Endパイプライン統合 + 確認UI構築
- Week 4: 本番データ50件で精度評価 + Go/NoGo判断
- 必要体制: エンジニア2名（4週間）+ 業務担当者1名（週2時間）

## 図解案
**図の種類**: ガントチャート（簡易版）
**描く内容**:
```
タスク              Week1  Week2  Week3  Week4
環境構築            ████
評価セット作成      ████
OCR精度比較                ████
LLM正規化テスト            ████
統合パイプライン                   ████
確認UI                             ████
本番データ評価                            ████
Go/NoGo判断                               ████

費用見積: AWS利用料 ~$50 + エンジニア工数
```

## トークトラック（30〜60秒）
「本格開発の前に、4週間・低コストで技術検証をします。評価セット50件を使ってOCR精度を測り、日本語の正規化が機能するか確認します。4週間後にGo/NoGoを判断し、問題があれば方向転換できます。投資対効果を確認してから本開発に進む設計です。」

---

---

# Slide 8: 成功条件

## タイトル
**数字で測る: KPIと評価基準を明確にする**

## 箇条書き（3〜5点）
- PoC成功条件: 抽出F1精度≥85% かつ 例外率≤15%
- MVP成功条件: 入力作業時間20%削減（Before/Afterで実測）
- 品質基準: 監査ログ100%記録 / PII漏洩ゼロ
- ユーザー受容: 「日常的に使いたい」回答70%以上（アンケート）
- ROI基準: 12ヶ月以内に初期投資を回収（工数削減換算）

## 図解案
**図の種類**: KPIダッシュボード（目標値 vs 現状）
**描く内容**:
```
KPI              現状      目標      計測方法
─────────────────────────────────────────
抽出精度（F1）   計測なし  ≥85%      評価セット
処理時間/件      〜5分     ≤1分      実測
入力ミス率        X%       X/3以下   エラーログ
オペレーター満足度 -        ≥70%     アンケート
月次コスト         Y円     Y+Z円    AWS請求
```
*現状値は仮定。実測後に埋める*

## トークトラック（30〜60秒）
「感覚的な評価では意思決定できません。数字で測ります。PoC期間中に評価セット50件で精度を定量測定し、作業時間もストップウォッチで計ります。4週間後の判断会議では、これらの数字を見てGo/NoGoを決めます。成功条件を事前に合意しておくことが重要です。」

---

---

# Slide 9: リスク

## タイトル
**主要リスクと対策: 想定済みだから怖くない**

## 箇条書き（3〜5点）
- リスク①【精度不足】OCR精度が85%に届かない → 対策: 前処理強化 / OSS OCRへの切り替え / 対象フォームを更に絞る
- リスク②【PII漏洩】氏名・口座番号がクラウドに送信される → 対策: 送信前マスキング必須化 / VPC内完結構成
- リスク③【形骸化】確認UIで全件OKを押すだけになる → 対策: 低信頼項目はスキップ不能なUI設計 / 抜き取り検査
- リスク④【RPA破綻】画面変更でRPAが誤動作 → 対策: RPAをAPI非対応システム限定に縛る / 変更検知アラート
- リスク⑤【現場抵抗】「自動化で仕事が減る」不安 → 対策: 「補助ツール」として位置付け。削減された工数を別業務に活用

## 図解案
**図の種類**: リスクマトリクス（2×2: 発生確率 × 影響度）
**描く内容**:
```
影響大│ ③PII漏洩   │ ①精度不足
      │ ④RPA破綻   │ ③形骸化
──────┼────────────┼────────────
影響小│            │ ⑤現場抵抗
      │            │
      └────────────┴────────────
           低確率       高確率
```
*各象限に対策ラベルを配置*

## トークトラック（30〜60秒）
「リスクを事前に洗い出し、対策を準備しました。最も重要なのはPIIリスクです。手順書に個人情報が含まれる場合、クラウドに送る前に必ずマスキング処理を挟みます。精度リスクはPoC期間で早期に発見し、対策を打てます。全てのリスクに対策があります。これが理由で止める話ではありません。」

---

---

# Slide 10: 依頼事項

## タイトル
**承認をいただきたいこと 3つ**

## 箇条書き（3〜5点）
- 依頼①: **PoC実施の承認** — エンジニア2名を4週間アサイン（Month 1）
- 依頼②: **評価用データの提供** — 実際の手順書画像 50件（PII含む場合はマスキング後）
- 依頼③: **Phase 1 MVP開発の事前合意** — PoC Go判定後に正式開始（Month 2〜3）
- 参考: PoC期間のAWSコスト見積 〜$50（約7,500円）
- 次のアクション: 本日中にPoC開始日を確定し、評価データ担当者を指名

## 図解案
**図の種類**: アクションプラン（タイムライン）
**描く内容**:
```
今日              2週間後          4週間後          3ヶ月後
  │                  │                │                │
[承認]────────→[PoC開始]───────→[Go/NoGo]────→[MVP完成]
  │                  │                │                │
依頼①承認       環境構築完了     判断会議         本番投入
依頼②データ      評価50件準備
依頼③合意
```

## トークトラック（30〜60秒）
「本日お願いしたいことは3つです。PoC実施の承認、評価用データの提供、そしてPoC成功後のMVP開発の事前合意です。4週間後にデータを持って再度報告します。その時点で精度が出なければ正直に報告し、方針を見直します。まず動かして検証する、それが最速の進め方です。ぜひGOをいただけますか。」

---

---

## 付録: 発表準備チェックリスト

```
□ Slide 1: 現状の数字（件数・作業時間）を実績値に差し替える
□ Slide 4: 比較表の「日本語精度」を社内フォームで実測した値に更新
□ Slide 6: MVP対象フォームを確定して記載
□ Slide 8: 「現状」欄を実測値で埋める
□ Slide 10: PoC開始希望日を記載

事前配布:
□ 本資料PDF（全10ページ）
□ 02_comparison_matrix.md（技術詳細補足）
□ 04_poc_plan.md（工数・コスト根拠）
```
